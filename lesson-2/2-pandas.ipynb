{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is the most popular data analysis library in Python. It is a powerful tool for data manipulation and analysis.\n",
    "\n",
    "Most of the time, our data is stored as a file on our hard drive. We can read the data into a Pandas DataFrame using pandas functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will explore the world happiness report data from Kaggle. Learn more about this dataset [here](https://www.kaggle.com/datasets/ajaypalsinghlo/world-happiness-report-2021?resource=download)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are basically doing a less impressive version of [this notebook](https://www.kaggle.com/code/joshuaswords/awesome-eda-2021-happiness-population)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import pandas. Make sure to install it if you get a `ModuleNotFoundError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... # importing pandas as 'pd' is standard practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can read the data into a DataFrame. We will use the `pd.read_csv` function. It takes two arguments: the path to the file, and the delimiter. \n",
    "\n",
    "The file we want to read is called `world_happiness_report.csv` and it's in the `data` folder. Therefore, the path that we want to pass in is `data/world_happiness_report.csv`. Notice that this path is relative to the location of the notebook.\n",
    "\n",
    "The delimiter has a default value of '`,`', which is what we want, so we don't need t pass it in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes have a bunch of useful methods that we can use to explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see what the columns are by using the .columns attribute\n",
    "...\n",
    "\n",
    "# we can see the shape of the data using the .shape attribute\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can get a summary of the data using the describe() method\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The head method displays the first 5 rows of the dataframe.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tail method displays the last 5 rows of the dataframe.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a quick analysis to see how life expectancy in Botswana has changed since we started collecting data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's extract the rows for Botswana. We can do that by indexing the DataFrame with the `Country name` column. We want rows where the value of the `Country name` column is `Botswana`, so we can use the `==` operator. This gets all of the row indexes where the value of the `Country name` column is `Botswana`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botswana_df = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot it using seaborn. Don't forget to import seaborn first.\n",
    "\n",
    "We want to plot `Healthy life expectancy at birth` as our y-axis and `year` as our x-axis. We can do this using the `sns.lineplot` function. We pass in the dataframe, the x-axis column, and the y-axis column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first import seaborn as sns\n",
    "...\n",
    "\n",
    "# seaborn has a .lineplot method\n",
    "# this method takes a dataframe in it's 'data' argument\n",
    "# we can also pass an x and y axis to the method, using names from the df\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pandas also has a `.plot` method that can be used to plot dataframes very quickly, but with less customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botswana_df.plot(x=\"year\", y=\"Healthy life expectancy at birth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this method to plot average life expectancy over time globally as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, however, we need to create a column for average life expectancy. We can do this by using the `.mean` method on the `Healthy ife expectancy at birth` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first use the .groupby method to group the data by 'year'\n",
    "df_by_year = ...\n",
    "\n",
    "# the .mean method returns the mean of each column in the group\n",
    "means = ...\n",
    "\n",
    "# plot it!\n",
    "means.plot(x=\"year\", y=\"Healthy life expectancy at birth\")\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you can see how easy it is to explore data using pandas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a more complex analysis, exploring `Positive affect` and `Perceptions of corruption`. First let's naively plot these two columns. We can do this by using the `sns.lineplot` function, put the dataframe in the `data` argument, and pass in the `Perceptions of corruption` column as the x-axis and the `Positive affect` as the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there might be a trend, but a lineplot is probably not the best for this. Let's try a scatterplot with linear regression. Seaborn has a function called `regplot` that can do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression makes the trend much more clear, but is this correlation statistically significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out using pandas and a new package called `scipy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running any analysis, let's make sure that the data is cleaned. In this case, our data has values that are set to NaN (not a number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there are nan?\n",
    "num_nan = df.isna().sum()\n",
    "print(\"\\tNumber of NaN by Column\")\n",
    "print(num_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we are missing a lot of data, especially in the perceptions of corruption column. For now, let's remove the rows with missing values. We can do this by using the `dropna` function.\n",
    "\n",
    "Depending on your analysis, you may wan't to fill in this data with another value. There is a `fillna` function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dropna to remove the rows with nan\n",
    "cleaned_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corruption = cleaned_df['Perceptions of corruption']\n",
    "positive_affect = cleaned_df['Positive affect']\n",
    "\n",
    "# pandas has a .corr method which will give us the correlation between two columns,\n",
    "# but not the p-value\n",
    "r = positive_affect.corr(corruption, method='pearson')\n",
    "print(\"pandas pearson correlation:\", r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works fine, but we want the statistical significance as well. Let's use the `scipy` package to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use scipy to calculate the significance of the correlation\n",
    "# import scipy.stats\n",
    "...\n",
    "\n",
    "# use scipy.stats.personr to calculate the correlation\n",
    "r, p = ...\n",
    "print(\"scipy pearson correlation:\", r, \"p-value:\", p)\n",
    "\n",
    "\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"The correlation is significant!\")\n",
    "else:\n",
    "    print(\"The correlation is not significant!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "More info on correlation in python https://realpython.com/numpy-scipy-pandas-correlation-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we want to see all of the correlations between the variables. We can use the `corr` function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "print(\"Correlation Matrix\")\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the significance of these correlations? Let's use `scipy` again. Here's an example of a function that can do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from: https://stackoverflow.com/questions/25571882/pandas-columns-correlation-with-statistical-significance\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_pvalues(df):\n",
    "    df = df.dropna()._get_numeric_data()\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            pvalues[r][c] = round(pearsonr(df[r], df[c])[1], 4)\n",
    "    return pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = calculate_pvalues(df) \n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more complicated code to show a nice table of correlations with significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "significance_levels = [0.01, 0.05, 0.1]\n",
    "\n",
    "x = corruption\n",
    "y = positive_affect\n",
    "rho = df.corr()\n",
    "pval = df.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "significance = pval.applymap(lambda x: ''.join(['*' for t in significance_levels if x<=t]))\n",
    "rho.round(2).astype(str) + significance"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f445f5e3151e12de572d6044d292a96d2963980967ced056e13cb018390e5303"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('intro')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
